#Neural Network
Basic implementation of a 2 layer fully connected neural network using ReLU activation function, SoftMax loss function and Stochastic Gradient Descent for the optimization phase. It has been built to be tested on the CIFAR-10 dataset, and adjusting some hyperparameters it can reach about 50% accuracy while testing.